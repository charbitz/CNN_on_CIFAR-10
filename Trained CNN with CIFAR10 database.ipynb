{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Trained CNN with CIFAR10 database.ipynb","provenance":[{"file_id":"19jR2PKbSq_cnkB0TuNMUviGhybdDvJNr","timestamp":1640548126792},{"file_id":"1jBW9gAZHJH-Bd5EsEGmyGCGKmSqhG6An","timestamp":1591477731963},{"file_id":"1OVgN9yqJjby55OWSjASdBAQGewpOY8zD","timestamp":1557473230489},{"file_id":"1Cs6sHPlRsXyChHdCZmHsJ5tsJnDvgh2K","timestamp":1557304357507},{"file_id":"1JQvhpR2Q2x-DRD_9zXmZu6AGdFPpIGgT","timestamp":1550301979712}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Digital Image Processing - Lab Project 2\n","\n","## Convolutional Neural Networks - Multi-class Classification\n","\n","This Colab Notebook was created in the context of the course Digital Image Processing from 8th semester at EECE DUTh.\n","\n","This is the second Lab Project, which was requested at that course.\n","\n","The purpose of this Project was to train a convolutional neural network (CNN), on the famous image dataset CIFAR10 efficiently enough. The wanted result was to succeed a final accuracy near 80% on testing data. Data augmentation was not allowed to be used. \n","\n","The following parameters could be changed:\n","\n","\n","> *   batch size \n","*   epochs \n","* At conv2d layer:\n","  * number of kernels\n","  * activation function type\n","* dropout\n","*  deletion or modification of layers at the fully connected layer\n","* At the optimizer:\n","  * learning rate \n","  * decay\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","The final accuracy on test data, the network had succeeded was 79,06% . "],"metadata":{"id":"eCx1H6fbinIE"}},{"cell_type":"code","metadata":{"id":"YuZ4iKj5EgVD","outputId":"8c9ede66-3eda-4bd7-d230-28c71f987179","executionInfo":{"status":"ok","timestamp":1592167222521,"user_tz":-180,"elapsed":1349024,"user":{"displayName":"Charalampos Bitz","photoUrl":"","userId":"17727372873056779286"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import numpy as np\n","\n","batch_size = 90 \n","num_classes = 10\n","epochs = 200\n","\n","# input image dimensions\n","img_rows, img_cols = 32, 32\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","x_train = x_train.reshape(50000,32,32,3)\n","x_test = x_test.reshape(10000,32,32,3)\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, kernel_size=(3, 3),  activation='relu', input_shape=(32,32,3)))\n","model.add(Conv2D(32, (3, 3),  activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='tanh', input_shape=(32,32,3)))\n","model.add(Conv2D(64, (3, 3),  activation='tanh'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv2D(512, kernel_size=(2, 2), activation='relu', input_shape=(32,32,3)))\n","model.add(Conv2D(512, (3, 3),  activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.1))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-3)\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/200\n","50000/50000 [==============================] - 7s 145us/step - loss: 1.7721 - accuracy: 0.3506 - val_loss: 1.3495 - val_accuracy: 0.5057\n","Epoch 2/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 1.3363 - accuracy: 0.5224 - val_loss: 1.2730 - val_accuracy: 0.5608\n","Epoch 3/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 1.1598 - accuracy: 0.5895 - val_loss: 1.1705 - val_accuracy: 0.6020\n","Epoch 4/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 1.0545 - accuracy: 0.6239 - val_loss: 0.9749 - val_accuracy: 0.6601\n","Epoch 5/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.9740 - accuracy: 0.6557 - val_loss: 0.9936 - val_accuracy: 0.6604\n","Epoch 6/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.9126 - accuracy: 0.6779 - val_loss: 0.8929 - val_accuracy: 0.6921\n","Epoch 7/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.8670 - accuracy: 0.6932 - val_loss: 1.0005 - val_accuracy: 0.6702\n","Epoch 8/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.8269 - accuracy: 0.7086 - val_loss: 0.8497 - val_accuracy: 0.7116\n","Epoch 9/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.7908 - accuracy: 0.7211 - val_loss: 0.8886 - val_accuracy: 0.7056\n","Epoch 10/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.7644 - accuracy: 0.7323 - val_loss: 0.8518 - val_accuracy: 0.7137\n","Epoch 11/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.7352 - accuracy: 0.7426 - val_loss: 0.8151 - val_accuracy: 0.7238\n","Epoch 12/200\n","50000/50000 [==============================] - 7s 138us/step - loss: 0.7156 - accuracy: 0.7486 - val_loss: 0.7791 - val_accuracy: 0.7372\n","Epoch 13/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.6933 - accuracy: 0.7576 - val_loss: 0.7807 - val_accuracy: 0.7372\n","Epoch 14/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.6799 - accuracy: 0.7619 - val_loss: 0.7854 - val_accuracy: 0.7395\n","Epoch 15/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.6594 - accuracy: 0.7679 - val_loss: 0.7825 - val_accuracy: 0.7440\n","Epoch 16/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.6460 - accuracy: 0.7738 - val_loss: 0.7974 - val_accuracy: 0.7413\n","Epoch 17/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.6350 - accuracy: 0.7770 - val_loss: 0.7771 - val_accuracy: 0.7436\n","Epoch 18/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.6165 - accuracy: 0.7801 - val_loss: 0.7651 - val_accuracy: 0.7482\n","Epoch 19/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.6071 - accuracy: 0.7859 - val_loss: 0.7283 - val_accuracy: 0.7590\n","Epoch 20/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5968 - accuracy: 0.7904 - val_loss: 0.7446 - val_accuracy: 0.7504\n","Epoch 21/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.5863 - accuracy: 0.7938 - val_loss: 0.7486 - val_accuracy: 0.7559\n","Epoch 22/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5777 - accuracy: 0.7962 - val_loss: 0.7310 - val_accuracy: 0.7575\n","Epoch 23/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5684 - accuracy: 0.7983 - val_loss: 0.7453 - val_accuracy: 0.7549\n","Epoch 24/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5630 - accuracy: 0.8028 - val_loss: 0.7493 - val_accuracy: 0.7611\n","Epoch 25/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5516 - accuracy: 0.8050 - val_loss: 0.7561 - val_accuracy: 0.7571\n","Epoch 26/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.5460 - accuracy: 0.8069 - val_loss: 0.7169 - val_accuracy: 0.7695\n","Epoch 27/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5351 - accuracy: 0.8102 - val_loss: 0.7387 - val_accuracy: 0.7612\n","Epoch 28/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.5317 - accuracy: 0.8130 - val_loss: 0.7371 - val_accuracy: 0.7622\n","Epoch 29/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.5221 - accuracy: 0.8169 - val_loss: 0.7446 - val_accuracy: 0.7627\n","Epoch 30/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.5160 - accuracy: 0.8187 - val_loss: 0.7326 - val_accuracy: 0.7665\n","Epoch 31/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5117 - accuracy: 0.8189 - val_loss: 0.7447 - val_accuracy: 0.7642\n","Epoch 32/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.5062 - accuracy: 0.8208 - val_loss: 0.7364 - val_accuracy: 0.7645\n","Epoch 33/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4980 - accuracy: 0.8231 - val_loss: 0.7452 - val_accuracy: 0.7655\n","Epoch 34/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4925 - accuracy: 0.8270 - val_loss: 0.7401 - val_accuracy: 0.7648\n","Epoch 35/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4901 - accuracy: 0.8285 - val_loss: 0.7171 - val_accuracy: 0.7706\n","Epoch 36/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4843 - accuracy: 0.8293 - val_loss: 0.7323 - val_accuracy: 0.7683\n","Epoch 37/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4787 - accuracy: 0.8310 - val_loss: 0.7413 - val_accuracy: 0.7667\n","Epoch 38/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4766 - accuracy: 0.8321 - val_loss: 0.7185 - val_accuracy: 0.7716\n","Epoch 39/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4667 - accuracy: 0.8348 - val_loss: 0.7369 - val_accuracy: 0.7683\n","Epoch 40/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4643 - accuracy: 0.8359 - val_loss: 0.7422 - val_accuracy: 0.7700\n","Epoch 41/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4607 - accuracy: 0.8361 - val_loss: 0.7200 - val_accuracy: 0.7721\n","Epoch 42/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4528 - accuracy: 0.8402 - val_loss: 0.7399 - val_accuracy: 0.7698\n","Epoch 43/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4504 - accuracy: 0.8424 - val_loss: 0.7209 - val_accuracy: 0.7755\n","Epoch 44/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4500 - accuracy: 0.8405 - val_loss: 0.7258 - val_accuracy: 0.7744\n","Epoch 45/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4422 - accuracy: 0.8430 - val_loss: 0.7255 - val_accuracy: 0.7731\n","Epoch 46/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4406 - accuracy: 0.8444 - val_loss: 0.7281 - val_accuracy: 0.7747\n","Epoch 47/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4372 - accuracy: 0.8475 - val_loss: 0.7458 - val_accuracy: 0.7690\n","Epoch 48/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4332 - accuracy: 0.8454 - val_loss: 0.7288 - val_accuracy: 0.7735\n","Epoch 49/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4338 - accuracy: 0.8473 - val_loss: 0.7187 - val_accuracy: 0.7758\n","Epoch 50/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4275 - accuracy: 0.8480 - val_loss: 0.7295 - val_accuracy: 0.7767\n","Epoch 51/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4275 - accuracy: 0.8496 - val_loss: 0.7290 - val_accuracy: 0.7765\n","Epoch 52/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4188 - accuracy: 0.8510 - val_loss: 0.7202 - val_accuracy: 0.7782\n","Epoch 53/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4216 - accuracy: 0.8525 - val_loss: 0.7292 - val_accuracy: 0.7768\n","Epoch 54/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4173 - accuracy: 0.8522 - val_loss: 0.7243 - val_accuracy: 0.7785\n","Epoch 55/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.4117 - accuracy: 0.8555 - val_loss: 0.7349 - val_accuracy: 0.7776\n","Epoch 56/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4079 - accuracy: 0.8568 - val_loss: 0.7237 - val_accuracy: 0.7799\n","Epoch 57/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.4076 - accuracy: 0.8564 - val_loss: 0.7340 - val_accuracy: 0.7777\n","Epoch 58/200\n","50000/50000 [==============================] - 7s 138us/step - loss: 0.4041 - accuracy: 0.8590 - val_loss: 0.7340 - val_accuracy: 0.7755\n","Epoch 59/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.4007 - accuracy: 0.8570 - val_loss: 0.7099 - val_accuracy: 0.7822\n","Epoch 60/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3985 - accuracy: 0.8598 - val_loss: 0.7441 - val_accuracy: 0.7748\n","Epoch 61/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.4002 - accuracy: 0.8585 - val_loss: 0.7167 - val_accuracy: 0.7778\n","Epoch 62/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3905 - accuracy: 0.8629 - val_loss: 0.7291 - val_accuracy: 0.7808\n","Epoch 63/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3909 - accuracy: 0.8620 - val_loss: 0.7183 - val_accuracy: 0.7814\n","Epoch 64/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3895 - accuracy: 0.8623 - val_loss: 0.7301 - val_accuracy: 0.7773\n","Epoch 65/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3917 - accuracy: 0.8604 - val_loss: 0.7263 - val_accuracy: 0.7779\n","Epoch 66/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3886 - accuracy: 0.8628 - val_loss: 0.7128 - val_accuracy: 0.7833\n","Epoch 67/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3807 - accuracy: 0.8658 - val_loss: 0.7240 - val_accuracy: 0.7827\n","Epoch 68/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3760 - accuracy: 0.8673 - val_loss: 0.7416 - val_accuracy: 0.7782\n","Epoch 69/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3806 - accuracy: 0.8642 - val_loss: 0.7154 - val_accuracy: 0.7817\n","Epoch 70/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3768 - accuracy: 0.8666 - val_loss: 0.7254 - val_accuracy: 0.7810\n","Epoch 71/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3747 - accuracy: 0.8684 - val_loss: 0.7151 - val_accuracy: 0.7843\n","Epoch 72/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3750 - accuracy: 0.8665 - val_loss: 0.7270 - val_accuracy: 0.7804\n","Epoch 73/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3711 - accuracy: 0.8694 - val_loss: 0.7320 - val_accuracy: 0.7795\n","Epoch 74/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3675 - accuracy: 0.8707 - val_loss: 0.7250 - val_accuracy: 0.7807\n","Epoch 75/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3661 - accuracy: 0.8701 - val_loss: 0.7129 - val_accuracy: 0.7847\n","Epoch 76/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3684 - accuracy: 0.8695 - val_loss: 0.7303 - val_accuracy: 0.7784\n","Epoch 77/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3653 - accuracy: 0.8709 - val_loss: 0.7165 - val_accuracy: 0.7823\n","Epoch 78/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3595 - accuracy: 0.8728 - val_loss: 0.7273 - val_accuracy: 0.7828\n","Epoch 79/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3580 - accuracy: 0.8725 - val_loss: 0.7225 - val_accuracy: 0.7821\n","Epoch 80/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3562 - accuracy: 0.8732 - val_loss: 0.7349 - val_accuracy: 0.7825\n","Epoch 81/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3583 - accuracy: 0.8722 - val_loss: 0.7256 - val_accuracy: 0.7830\n","Epoch 82/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3558 - accuracy: 0.8748 - val_loss: 0.7233 - val_accuracy: 0.7828\n","Epoch 83/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3557 - accuracy: 0.8752 - val_loss: 0.7365 - val_accuracy: 0.7779\n","Epoch 84/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3498 - accuracy: 0.8749 - val_loss: 0.7402 - val_accuracy: 0.7812\n","Epoch 85/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3496 - accuracy: 0.8774 - val_loss: 0.7320 - val_accuracy: 0.7823\n","Epoch 86/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3481 - accuracy: 0.8780 - val_loss: 0.7384 - val_accuracy: 0.7812\n","Epoch 87/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3475 - accuracy: 0.8770 - val_loss: 0.7305 - val_accuracy: 0.7813\n","Epoch 88/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3443 - accuracy: 0.8773 - val_loss: 0.7293 - val_accuracy: 0.7839\n","Epoch 89/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3454 - accuracy: 0.8774 - val_loss: 0.7298 - val_accuracy: 0.7855\n","Epoch 90/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3466 - accuracy: 0.8782 - val_loss: 0.7257 - val_accuracy: 0.7829\n","Epoch 91/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3456 - accuracy: 0.8774 - val_loss: 0.7109 - val_accuracy: 0.7861\n","Epoch 92/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3417 - accuracy: 0.8786 - val_loss: 0.7274 - val_accuracy: 0.7838\n","Epoch 93/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3392 - accuracy: 0.8803 - val_loss: 0.7237 - val_accuracy: 0.7855\n","Epoch 94/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3384 - accuracy: 0.8794 - val_loss: 0.7303 - val_accuracy: 0.7824\n","Epoch 95/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3377 - accuracy: 0.8796 - val_loss: 0.7348 - val_accuracy: 0.7831\n","Epoch 96/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3365 - accuracy: 0.8809 - val_loss: 0.7284 - val_accuracy: 0.7854\n","Epoch 97/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3336 - accuracy: 0.8794 - val_loss: 0.7322 - val_accuracy: 0.7840\n","Epoch 98/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3342 - accuracy: 0.8810 - val_loss: 0.7171 - val_accuracy: 0.7863\n","Epoch 99/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3296 - accuracy: 0.8834 - val_loss: 0.7310 - val_accuracy: 0.7843\n","Epoch 100/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3297 - accuracy: 0.8842 - val_loss: 0.7303 - val_accuracy: 0.7867\n","Epoch 101/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3335 - accuracy: 0.8824 - val_loss: 0.7264 - val_accuracy: 0.7843\n","Epoch 102/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3317 - accuracy: 0.8827 - val_loss: 0.7307 - val_accuracy: 0.7828\n","Epoch 103/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3303 - accuracy: 0.8827 - val_loss: 0.7266 - val_accuracy: 0.7847\n","Epoch 104/200\n","50000/50000 [==============================] - 7s 138us/step - loss: 0.3260 - accuracy: 0.8845 - val_loss: 0.7491 - val_accuracy: 0.7833\n","Epoch 105/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3292 - accuracy: 0.8829 - val_loss: 0.7409 - val_accuracy: 0.7839\n","Epoch 106/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3224 - accuracy: 0.8868 - val_loss: 0.7328 - val_accuracy: 0.7852\n","Epoch 107/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3225 - accuracy: 0.8874 - val_loss: 0.7416 - val_accuracy: 0.7838\n","Epoch 108/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3226 - accuracy: 0.8853 - val_loss: 0.7375 - val_accuracy: 0.7849\n","Epoch 109/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3206 - accuracy: 0.8859 - val_loss: 0.7293 - val_accuracy: 0.7848\n","Epoch 110/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.3174 - accuracy: 0.8881 - val_loss: 0.7316 - val_accuracy: 0.7847\n","Epoch 111/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3212 - accuracy: 0.8859 - val_loss: 0.7339 - val_accuracy: 0.7844\n","Epoch 112/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3235 - accuracy: 0.8856 - val_loss: 0.7334 - val_accuracy: 0.7865\n","Epoch 113/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3174 - accuracy: 0.8876 - val_loss: 0.7354 - val_accuracy: 0.7859\n","Epoch 114/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3175 - accuracy: 0.8890 - val_loss: 0.7385 - val_accuracy: 0.7863\n","Epoch 115/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3120 - accuracy: 0.8903 - val_loss: 0.7315 - val_accuracy: 0.7877\n","Epoch 116/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3059 - accuracy: 0.8940 - val_loss: 0.7419 - val_accuracy: 0.7869\n","Epoch 117/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3127 - accuracy: 0.8902 - val_loss: 0.7314 - val_accuracy: 0.7879\n","Epoch 118/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3098 - accuracy: 0.8904 - val_loss: 0.7334 - val_accuracy: 0.7883\n","Epoch 119/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3124 - accuracy: 0.8886 - val_loss: 0.7425 - val_accuracy: 0.7853\n","Epoch 120/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3105 - accuracy: 0.8903 - val_loss: 0.7323 - val_accuracy: 0.7869\n","Epoch 121/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3088 - accuracy: 0.8912 - val_loss: 0.7350 - val_accuracy: 0.7867\n","Epoch 122/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3071 - accuracy: 0.8917 - val_loss: 0.7433 - val_accuracy: 0.7876\n","Epoch 123/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3056 - accuracy: 0.8925 - val_loss: 0.7435 - val_accuracy: 0.7851\n","Epoch 124/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3050 - accuracy: 0.8929 - val_loss: 0.7407 - val_accuracy: 0.7854\n","Epoch 125/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3084 - accuracy: 0.8899 - val_loss: 0.7364 - val_accuracy: 0.7863\n","Epoch 126/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.3028 - accuracy: 0.8916 - val_loss: 0.7334 - val_accuracy: 0.7869\n","Epoch 127/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3015 - accuracy: 0.8932 - val_loss: 0.7347 - val_accuracy: 0.7900\n","Epoch 128/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3004 - accuracy: 0.8936 - val_loss: 0.7325 - val_accuracy: 0.7898\n","Epoch 129/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2970 - accuracy: 0.8953 - val_loss: 0.7480 - val_accuracy: 0.7861\n","Epoch 130/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3024 - accuracy: 0.8930 - val_loss: 0.7331 - val_accuracy: 0.7885\n","Epoch 131/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3033 - accuracy: 0.8928 - val_loss: 0.7366 - val_accuracy: 0.7889\n","Epoch 132/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.3042 - accuracy: 0.8934 - val_loss: 0.7385 - val_accuracy: 0.7877\n","Epoch 133/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2996 - accuracy: 0.8951 - val_loss: 0.7407 - val_accuracy: 0.7872\n","Epoch 134/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2963 - accuracy: 0.8965 - val_loss: 0.7402 - val_accuracy: 0.7872\n","Epoch 135/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2957 - accuracy: 0.8962 - val_loss: 0.7375 - val_accuracy: 0.7895\n","Epoch 136/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2941 - accuracy: 0.8980 - val_loss: 0.7484 - val_accuracy: 0.7863\n","Epoch 137/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2988 - accuracy: 0.8950 - val_loss: 0.7327 - val_accuracy: 0.7887\n","Epoch 138/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2922 - accuracy: 0.8972 - val_loss: 0.7350 - val_accuracy: 0.7897\n","Epoch 139/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2921 - accuracy: 0.8964 - val_loss: 0.7435 - val_accuracy: 0.7863\n","Epoch 140/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.2912 - accuracy: 0.8959 - val_loss: 0.7382 - val_accuracy: 0.7882\n","Epoch 141/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2912 - accuracy: 0.8987 - val_loss: 0.7447 - val_accuracy: 0.7857\n","Epoch 142/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2898 - accuracy: 0.8985 - val_loss: 0.7479 - val_accuracy: 0.7860\n","Epoch 143/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2880 - accuracy: 0.8993 - val_loss: 0.7372 - val_accuracy: 0.7915\n","Epoch 144/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2921 - accuracy: 0.8962 - val_loss: 0.7334 - val_accuracy: 0.7912\n","Epoch 145/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2921 - accuracy: 0.8970 - val_loss: 0.7403 - val_accuracy: 0.7873\n","Epoch 146/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2897 - accuracy: 0.8972 - val_loss: 0.7467 - val_accuracy: 0.7875\n","Epoch 147/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2899 - accuracy: 0.8968 - val_loss: 0.7417 - val_accuracy: 0.7874\n","Epoch 148/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2932 - accuracy: 0.8970 - val_loss: 0.7428 - val_accuracy: 0.7866\n","Epoch 149/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2876 - accuracy: 0.8991 - val_loss: 0.7431 - val_accuracy: 0.7884\n","Epoch 150/200\n","50000/50000 [==============================] - 7s 137us/step - loss: 0.2880 - accuracy: 0.8981 - val_loss: 0.7410 - val_accuracy: 0.7876\n","Epoch 151/200\n","50000/50000 [==============================] - 7s 138us/step - loss: 0.2883 - accuracy: 0.8987 - val_loss: 0.7416 - val_accuracy: 0.7877\n","Epoch 152/200\n","50000/50000 [==============================] - 7s 138us/step - loss: 0.2845 - accuracy: 0.8980 - val_loss: 0.7420 - val_accuracy: 0.7880\n","Epoch 153/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2839 - accuracy: 0.9002 - val_loss: 0.7444 - val_accuracy: 0.7886\n","Epoch 154/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2853 - accuracy: 0.8985 - val_loss: 0.7415 - val_accuracy: 0.7892\n","Epoch 155/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2822 - accuracy: 0.9002 - val_loss: 0.7500 - val_accuracy: 0.7863\n","Epoch 156/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2790 - accuracy: 0.9012 - val_loss: 0.7476 - val_accuracy: 0.7890\n","Epoch 157/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2807 - accuracy: 0.9008 - val_loss: 0.7500 - val_accuracy: 0.7886\n","Epoch 158/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2819 - accuracy: 0.9007 - val_loss: 0.7452 - val_accuracy: 0.7883\n","Epoch 159/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2806 - accuracy: 0.8997 - val_loss: 0.7460 - val_accuracy: 0.7904\n","Epoch 160/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2791 - accuracy: 0.9019 - val_loss: 0.7444 - val_accuracy: 0.7897\n","Epoch 161/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2760 - accuracy: 0.9032 - val_loss: 0.7441 - val_accuracy: 0.7900\n","Epoch 162/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2781 - accuracy: 0.9012 - val_loss: 0.7592 - val_accuracy: 0.7876\n","Epoch 163/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2815 - accuracy: 0.9006 - val_loss: 0.7468 - val_accuracy: 0.7895\n","Epoch 164/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2744 - accuracy: 0.9035 - val_loss: 0.7468 - val_accuracy: 0.7869\n","Epoch 165/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2779 - accuracy: 0.9010 - val_loss: 0.7396 - val_accuracy: 0.7893\n","Epoch 166/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2730 - accuracy: 0.9030 - val_loss: 0.7530 - val_accuracy: 0.7864\n","Epoch 167/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2765 - accuracy: 0.9017 - val_loss: 0.7404 - val_accuracy: 0.7913\n","Epoch 168/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2729 - accuracy: 0.9045 - val_loss: 0.7514 - val_accuracy: 0.7890\n","Epoch 169/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2802 - accuracy: 0.9005 - val_loss: 0.7491 - val_accuracy: 0.7879\n","Epoch 170/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2743 - accuracy: 0.9031 - val_loss: 0.7442 - val_accuracy: 0.7905\n","Epoch 171/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2745 - accuracy: 0.9032 - val_loss: 0.7525 - val_accuracy: 0.7871\n","Epoch 172/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.2766 - accuracy: 0.9033 - val_loss: 0.7509 - val_accuracy: 0.7868\n","Epoch 173/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2723 - accuracy: 0.9042 - val_loss: 0.7514 - val_accuracy: 0.7887\n","Epoch 174/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2712 - accuracy: 0.9046 - val_loss: 0.7516 - val_accuracy: 0.7869\n","Epoch 175/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2719 - accuracy: 0.9033 - val_loss: 0.7467 - val_accuracy: 0.7894\n","Epoch 176/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2699 - accuracy: 0.9050 - val_loss: 0.7495 - val_accuracy: 0.7882\n","Epoch 177/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2697 - accuracy: 0.9056 - val_loss: 0.7523 - val_accuracy: 0.7888\n","Epoch 178/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.2705 - accuracy: 0.9044 - val_loss: 0.7515 - val_accuracy: 0.7889\n","Epoch 179/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2716 - accuracy: 0.9033 - val_loss: 0.7424 - val_accuracy: 0.7889\n","Epoch 180/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2702 - accuracy: 0.9035 - val_loss: 0.7499 - val_accuracy: 0.7893\n","Epoch 181/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2666 - accuracy: 0.9058 - val_loss: 0.7498 - val_accuracy: 0.7892\n","Epoch 182/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.2666 - accuracy: 0.9057 - val_loss: 0.7500 - val_accuracy: 0.7894\n","Epoch 183/200\n","50000/50000 [==============================] - 7s 135us/step - loss: 0.2675 - accuracy: 0.9065 - val_loss: 0.7535 - val_accuracy: 0.7891\n","Epoch 184/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2666 - accuracy: 0.9054 - val_loss: 0.7607 - val_accuracy: 0.7856\n","Epoch 185/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2644 - accuracy: 0.9062 - val_loss: 0.7550 - val_accuracy: 0.7883\n","Epoch 186/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2678 - accuracy: 0.9046 - val_loss: 0.7566 - val_accuracy: 0.7883\n","Epoch 187/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2666 - accuracy: 0.9055 - val_loss: 0.7507 - val_accuracy: 0.7902\n","Epoch 188/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2651 - accuracy: 0.9054 - val_loss: 0.7499 - val_accuracy: 0.7903\n","Epoch 189/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.2619 - accuracy: 0.9064 - val_loss: 0.7564 - val_accuracy: 0.7874\n","Epoch 190/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.2640 - accuracy: 0.9071 - val_loss: 0.7644 - val_accuracy: 0.7892\n","Epoch 191/200\n","50000/50000 [==============================] - 7s 132us/step - loss: 0.2674 - accuracy: 0.9056 - val_loss: 0.7515 - val_accuracy: 0.7901\n","Epoch 192/200\n","50000/50000 [==============================] - 7s 132us/step - loss: 0.2607 - accuracy: 0.9080 - val_loss: 0.7550 - val_accuracy: 0.7893\n","Epoch 193/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.2659 - accuracy: 0.9070 - val_loss: 0.7501 - val_accuracy: 0.7912\n","Epoch 194/200\n","50000/50000 [==============================] - 7s 133us/step - loss: 0.2582 - accuracy: 0.9092 - val_loss: 0.7466 - val_accuracy: 0.7907\n","Epoch 195/200\n","50000/50000 [==============================] - 7s 134us/step - loss: 0.2585 - accuracy: 0.9097 - val_loss: 0.7530 - val_accuracy: 0.7922\n","Epoch 196/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.2609 - accuracy: 0.9060 - val_loss: 0.7505 - val_accuracy: 0.7893\n","Epoch 197/200\n","50000/50000 [==============================] - 7s 138us/step - loss: 0.2604 - accuracy: 0.9080 - val_loss: 0.7556 - val_accuracy: 0.7902\n","Epoch 198/200\n","50000/50000 [==============================] - 7s 137us/step - loss: 0.2615 - accuracy: 0.9073 - val_loss: 0.7542 - val_accuracy: 0.7904\n","Epoch 199/200\n","50000/50000 [==============================] - 7s 137us/step - loss: 0.2637 - accuracy: 0.9071 - val_loss: 0.7561 - val_accuracy: 0.7878\n","Epoch 200/200\n","50000/50000 [==============================] - 7s 136us/step - loss: 0.2600 - accuracy: 0.9076 - val_loss: 0.7491 - val_accuracy: 0.7906\n","Test loss: 0.7490973481178284\n","Test accuracy: 0.7906000018119812\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-2sa8xjTsRWk","outputId":"420667bc-069b-49d5-85c0-8c765f71500a","executionInfo":{"status":"ok","timestamp":1592167492073,"user_tz":-180,"elapsed":659,"user":{"displayName":"Charalampos Bitz","photoUrl":"","userId":"17727372873056779286"}},"colab":{"base_uri":"https://localhost:8080/","height":317}},"source":["from matplotlib import pyplot as plt\n","import cv2\n","img = cv2.imread('horse1.jpg')\n","newimg = cv2.resize(img,(32,32))\n","plt.imshow(newimg)\n","plt.show()\n","im2arr = newimg.reshape(1,32,32,3)\n","y_pred = model.predict(im2arr)\n","print(y_pred)\n","number = np.argmax(y_pred)\n","print ('The image is', number)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["[[6.1177734e-09 1.4026222e-13 3.3546266e-11 2.2242799e-10 1.3898828e-08\n","  9.7508163e-08 8.8373023e-15 9.9999988e-01 1.6170957e-13 6.8572495e-11]]\n","The image is 7\n"],"name":"stdout"}]}]}